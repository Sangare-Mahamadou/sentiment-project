{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4ff224ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "29cfb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cookies(driver: webdriver.Firefox, social_media: str, file: str) -> bool:\n",
    "    \"\"\"Charger et injecter les cookies Facebook\"\"\"\n",
    "    try:\n",
    "        driver.get(social_media)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        with open(file, \"r\", encoding=\"utf-8\") as file:\n",
    "            cookies_data = json.load(file)\n",
    "        \n",
    "        # Extraire la liste des cookies du dictionnaire\n",
    "        cookies = cookies_data[\"cookies\"] if \"cookies\" in cookies_data else cookies_data\n",
    "        \n",
    "        print(f\"{len(cookies)} cookies chargés depuis le fichier\")\n",
    "        \n",
    "        for cookie in cookies:\n",
    "            # Créer une copie du cookie pour éviter de modifier l'original\n",
    "            clean_cookie = cookie.copy()\n",
    "            \n",
    "            # Supprimer les attributs qui peuvent causer des problèmes avec Selenium\n",
    "            for key in [\"sameSite\", \"storeId\", \"id\", \"hostOnly\", \"session\"]:\n",
    "                clean_cookie.pop(key, None)\n",
    "                \n",
    "            try:\n",
    "                driver.add_cookie(clean_cookie)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur avec le cookie {cookie.get('name', 'inconnu')}: {e}\")\n",
    "        \n",
    "        print(\"Cookies injectés avec succès\")\n",
    "        return True\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Fichier facebook_cookies.json non trouvé!\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des cookies: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9580cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_driver() -> webdriver.Firefox:\n",
    "  opts = Options()\n",
    "  \n",
    "  # avec firefox\n",
    "\n",
    "  # Forcer un user-agent desktop\n",
    "  # desktop_ua = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0 Safari/537.36\"\n",
    "  # opts.set_preference(\"general.useragent.override\", desktop_ua)\n",
    "  # Ajuster l'échelle pour éviter rendu mobile\n",
    "  # opts.set_preference(\"layout.css.devPixelsPerPx\", \"1.0\")\n",
    "\n",
    "  # srv = Service(executable_path=r'/snap/bin/firefox.geckodriver')\n",
    "  # driver = webdriver.Firefox(options=opts, service=srv)\n",
    "  # driver.set_window_size(1920, 1080)\n",
    "  # Ou avec chrome \n",
    "\n",
    "  \n",
    "  desktop_ua = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0  0.0 Safari/537.36\"\n",
    "  opts.add_argument(f\"--user-agent={desktop_ua}\")\n",
    "  opts.add_argument(\"--window-size=1920,1080\")\n",
    "  opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "  driver = webdriver.Chrome(options=opts)\n",
    "  \n",
    "  return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0d005d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments_text(post_container, driver) -> list:\n",
    "    \"\"\"Extraire le texte des commentaires depuis le conteneur de post\"\"\"\n",
    "\n",
    "    try:\n",
    "        show_comments_btn = post_container.find_element(By.XPATH, './/div/div/div/div/div/div/div/div/div/div/div/div[13]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[2]/div[2]')\n",
    "        show_comments_btn.click()\n",
    "        time.sleep(10)\n",
    "        # comment_dialog = driver.find_element(By.XPATH, '//div[contains(@role, \"dialog\")]')\n",
    "\n",
    "        close_dialog_btn = driver.find_element(By.XPATH, '//div[contains(@role, \"dialog\")]//div[contains(@aria-label, \"Fermer\")]')\n",
    "\n",
    "        scrollable_container = driver.find_element(By.XPATH, '//div[contains(@role, \"dialog\")]/div/div[1]/div/div[2]')\n",
    "\n",
    "        # Essayer de trouver le conteneur de commentaires, sinon utiliser le conteneur scrollable\n",
    "        try:\n",
    "            comments_container = scrollable_container.find_element(By.XPATH, './/div[2]/div/div/div[2]/div/div[2]')\n",
    "            print(\"Conteneur de commentaires trouvé\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Conteneur de commentaires non trouvé - utilisation du conteneur scrollable\")\n",
    "            print(\"fermeture du dialogue des commentaires\")\n",
    "            close_dialog_btn.click()\n",
    "            \n",
    "            return []\n",
    "        \n",
    "        comments = []\n",
    "        previous_count = 0\n",
    "        no_change_iterations = 0\n",
    "        max_scrolls = 30  # Sécurité\n",
    "        scroll_count = 0\n",
    "        \n",
    "        while scroll_count < max_scrolls:\n",
    "\n",
    "            # try:\n",
    "\n",
    "            #     voir_reponses_btns = comments_container.find_elements(\n",
    "            #         By.XPATH, \n",
    "            #         \".//div[contains(text(), 'Voir') and (contains(text(), 'réponse') or contains(text(), 'réponses'))]\"\n",
    "            #     )\n",
    "            #     for btn in voir_reponses_btns:\n",
    "            #         try:\n",
    "            #             btn.click()\n",
    "            #             time.sleep(2)\n",
    "            #         except:\n",
    "            #             continue\n",
    "            # except NoSuchElementException:\n",
    "            #     print(\"some shit\")\n",
    "            #     pass\n",
    "                \n",
    "            comments_text = comments_container.find_elements(By.XPATH, './/div/span[@dir=\"auto\"]')\n",
    "            current_count = len(comments_text)\n",
    "            \n",
    "            # print(current_count, previous_count)\n",
    "            # Si le nombre n'a pas changé après plusieurs tentatives\n",
    "            if current_count == previous_count:\n",
    "                no_change_iterations += 1\n",
    "                if no_change_iterations >= 6:  # 3 fois sans changement = fin\n",
    "                    print(\"Fin du chargement des commentaires\")\n",
    "                    break\n",
    "            else:\n",
    "                no_change_iterations = 0  # Reset si nouveaux commentaires\n",
    "            \n",
    "            previous_count = current_count\n",
    "            scroll_count += 1\n",
    "            \n",
    "            # Scroller\n",
    "            driver.execute_script(\"\"\"\n",
    "                var container = arguments[0];\n",
    "                container.scrollBy(0, container.clientHeight);\n",
    "            \"\"\", scrollable_container)\n",
    "            \n",
    "            time.sleep(6)  \n",
    "        \n",
    "\n",
    "        comments = [comment.text for comment in comments_text if comment.text.strip() != '']\n",
    "        print(\"fermeture du dialogue des commentaires\")\n",
    "        close_dialog_btn.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur': {e}\")\n",
    "        return []\n",
    "\n",
    "    return set(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eacc2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraped_facebook_comments(driver: webdriver.Firefox, group_link) -> list:\n",
    "    \"\"\"Scraper les commentaires d'un post Facebook donné\"\"\"\n",
    "    driver.get(group_link)\n",
    "    time.sleep(15)\n",
    "    \n",
    "    comments = []\n",
    "    previous_count = 0\n",
    "    no_change_iterations = 0\n",
    "    all_ready_taken = set()\n",
    "    max_scrolls = 300 \n",
    "    scroll_count = 0\n",
    "\n",
    "    # container = driver.find_element(By.CSS_SELECTOR, 'div[id*=\"mount\"]')\n",
    "    post_container_height = 0\n",
    "\n",
    "    while scroll_count < max_scrolls:\n",
    "        div_ctn_index = len(driver.find_elements(By.XPATH, '//*[contains(@id, \"mount\")]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div[2]/div/div[2]/div'))\n",
    "        \n",
    "        post_containers = driver.find_elements(By.XPATH, '//*[contains(@id, \"mount\")]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div[2]/div/div[2]/div[last()]/div')\n",
    "\n",
    "        if post_container_height == 0 and len(post_containers) > 0:\n",
    "            post_container_height = driver.execute_script(\"\"\"\n",
    "                return arguments[0].clientHeight;\n",
    "            \"\"\", post_containers[0])\n",
    "\n",
    "        for post in post_containers:\n",
    "            try:\n",
    "                post_link = post.find_elements(By.XPATH, \".//a\")[2].get_attribute('href')\n",
    "                print(f\"Traitement du post: {post_link}\")\n",
    "                if post_link.lower() in all_ready_taken:\n",
    "                    continue\n",
    "                \n",
    "                all_ready_taken.add(post_link.lower())\n",
    "                \n",
    "                new_comments = extract_comments_text(post, driver)\n",
    "                comments.extend(list(new_comments))\n",
    "                print(f\"  → {len(new_comments)} commentaires récupérés\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur sur un post: {e}\")\n",
    "                continue\n",
    "        \n",
    "        current_count = len(all_ready_taken)\n",
    "        print(f\"Total posts facebook traités: {current_count}\")\n",
    "        print(f\"Total commentaires facebook: {len(comments)}\")\n",
    "        \n",
    "        # Vérifier si on a de nouveaux posts\n",
    "        print(no_change_iterations)\n",
    "        if current_count == previous_count and current_count != 0:\n",
    "            no_change_iterations += 1\n",
    "            if no_change_iterations >= 50:\n",
    "                print(\"no change in posts, stopping scroll three times\")\n",
    "                break\n",
    "        else:\n",
    "            no_change_iterations = 0\n",
    "        \n",
    "        previous_count = current_count\n",
    "        scroll_count += 1\n",
    "        \n",
    "        # Scroller de 5 posts (5 × hauteur d'un post)\n",
    "        if post_container_height > 0:\n",
    "            scroll_amount = post_container_height * 5\n",
    "            driver.execute_script(\"\"\"\n",
    "                var scrollAmount = arguments[0];\n",
    "                window.scrollBy({\n",
    "                    top: scrollAmount,\n",
    "                    behavior: 'smooth'\n",
    "                });\n",
    "            \"\"\", scroll_amount)\n",
    "        else:\n",
    "            # Fallback si hauteur pas détectée\n",
    "            driver.execute_script(\"window.scrollBy(0, 3000);\")\n",
    "        \n",
    "        print(\"Scrolling...\", scroll_count, max_scrolls )\n",
    "        time.sleep(3)  \n",
    "\n",
    "    \n",
    "    print(f\"\\n=== Scraping terminé ===\")\n",
    "    print(f\"Total posts traités: {len(all_ready_taken)}\")\n",
    "    print(f\"Total commentaires: {len(comments)}\")\n",
    "\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e1ae215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_at_bottom(driver: webdriver.Firefox, pause_time: int = 2):\n",
    "    \"\"\"Faire défiler la page jusqu'en bas pour charger plus de contenu\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(pause_time)\n",
    "        \n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def scraped_linkedin_comments(driver: webdriver.Firefox) -> list:\n",
    "    \"\"\"Scraper les commentaires d'un post LinkedIn donné\"\"\"\n",
    "    driver.get(\"https://www.linkedin.com/company/fnac/\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.find_element(By.CSS_SELECTOR, 'a.fastrack-sign-in-cta').click()\n",
    "    comments = []\n",
    "    \n",
    "    scroll_at_bottom(driver, pause_time=5)\n",
    "    posts = driver.find_elements(By.CSS_SELECTOR, \"div.fie-impression-container\")\n",
    "    for post in posts: \n",
    "        try:\n",
    "            show_comments_btn = post.find_element(By.CSS_SELECTOR, \"ul ul > li > button[aria-label*='comm']\")\n",
    "            show_comments_btn.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    post.find_element(By.CSS_SELECTOR, \"a[data-test-id='main-feed-activity-card-with-comments__see-more-comments']\").click()\n",
    "                except NoSuchElementException:\n",
    "                    break\n",
    "                time.sleep(3)\n",
    "\n",
    "            comments = post.find_elements(By.CSS_SELECTOR, \"span.comments-comment-item__main-content\")\n",
    "            for comment in comments:\n",
    "                comments.append(comment.text)\n",
    "        except NoSuchElementException :\n",
    "            continue\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7b959017",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media = [\n",
    "  # {\n",
    "  #   \"name\": \"facebook\",\n",
    "  #   \"url\": \"https://web.facebook.com\",\n",
    "  #   \"page_url\": \"https://web.facebook.com/Fnac\",\n",
    "  #   \"scrape_function\": scraped_facebook_comments,\n",
    "  #   \"cookies_file\": \"facebook.json\"\n",
    "  # },\n",
    "  {\n",
    "    \"name\": \"facebook\",\n",
    "    \"url\": \"https://web.facebook.com\",\n",
    "    \"page_url\": \"https://www.facebook.com/wavecotedivoire\",\n",
    "    \"scrape_function\": scraped_facebook_comments,\n",
    "    \"cookies_file\": \"facebook.json\"\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "168ce2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 cookies chargés depuis le fichier\n",
      "Cookies injectés avec succès\n",
      "Traitement du post: https://web.facebook.com/wavecotedivoire?__cft__[0]=AZXUW4hkp_u37EIJMqkbInCzonNwJna7KFd4WNsuv3BCSS1AeKGr-lidIaKu7X6CSr5lCV8mXCQb6NVDkanCx6kAaPuF0_iH4bRds0A6eN1sFSXPdOgS03XkICP9GKaUn2mpffviQcjL0giGcY6U5nXYkGRTXYD6LkQ4L0Q3wEyxS1KJSFUSr003bdm1-Wk2xhA&__tn__=%2CO%2CP-R#?gdi\n",
      "Conteneur de commentaires trouvé\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m         driver.refresh()\n\u001b[32m      6\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     comments.extend(\u001b[43msm\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscrape_function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msm\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpage_url\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     10\u001b[39m     driver.quit()\n\u001b[32m     13\u001b[39m df = pd.DataFrame({\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcomments\u001b[39m\u001b[33m'\u001b[39m: comments\n\u001b[32m     15\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mscraped_facebook_comments\u001b[39m\u001b[34m(driver, group_link)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     33\u001b[39m all_ready_taken.add(post_link.lower())\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m new_comments = \u001b[43mextract_comments_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m comments.extend(\u001b[38;5;28mlist\u001b[39m(new_comments))\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_comments)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m commentaires récupérés\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mextract_comments_text\u001b[39m\u001b[34m(post_container, driver)\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Scroller\u001b[39;00m\n\u001b[32m     66\u001b[39m     driver.execute_script(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[33m        var container = arguments[0];\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[33m        container.scrollBy(0, container.clientHeight);\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m, scrollable_container)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[32m     74\u001b[39m comments = [comment.text \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments_text \u001b[38;5;28;01mif\u001b[39;00m comment.text.strip() != \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfermeture du dialogue des commentaires\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "comments = list()\n",
    "for sm in social_media:\n",
    "    driver = init_driver()\n",
    "    if load_cookies(driver, sm['url'], sm['cookies_file']):\n",
    "        driver.refresh()\n",
    "    time.sleep(15)\n",
    "\n",
    "    comments.extend(sm[\"scrape_function\"](driver, sm['page_url']))\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'comments': comments\n",
    "})\n",
    "df.to_csv('comments_wave.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72581f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 1477)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comments.nunique(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ac8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "  'comments': df.comments.unique()\n",
    "}).to_csv('comments_cleaned_wave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install python-docx wordcloud spacy fasttext --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download fr_core_news_sm\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9cffcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
